# List of good references

This is a list of good references and reading material you can refer to throughout the workshop.  
You will also find a glossary in case there are any words you are unsure of.  


## References
- [ai-on-openshift](https://ai-on-openshift.io/) - A great resource for deploying and managing AI applications on OpenShift, often using Red Hat's AI suite.
- [ai-on-openshift/gitops](https://ai-on-openshift.io/odh-rhoai/gitops/) - How to create OpenShift AI resources through kubernetes yaml files.
- [Data Science Tutorial](https://www.w3schools.com/datascience/default.asp) - Code and guides for how you can use Python for Data Science with executable examples.
- [How Neural Networks Work Playlist](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) - A fantastic video guide that covers the basics of Neural Networks.
- [Tensorflow Playgrounds](https://playground.tensorflow.org/) - Tensorflow Plagrounds lets you play around with different settings and data for a small neural network to get a better understanding how it works.
- [Made With ML](https://madewithml.com/) - A extensive guide on ML and its lifecycle.
- [Google MLOps Blog](https://cloud.google.com/architecture/mlops-continuous-delivery-and-automation-pipelines-in-machine-learning) - Blog on the different stages of MLOps maturity, how you can transition between them and what you can see included in each stage.
- [Cookie Cutter Project Structure](https://cookiecutter-data-science.drivendata.org/) - A tool to initialize a data science project with a good project structure.

## Docs for AI Tools used
- [OpenShift AI](https://docs.redhat.com/en/documentation/red_hat_openshift_ai_self-managed/2-latest)
- [Kubeflow Pipelines](https://www.kubeflow.org/docs/components/pipelines/)
    - [Kubeflow Pipelines SDK](https://kubeflow-pipelines.readthedocs.io/en/sdk-2.12.0/)
    - [Kubeflow Pipelines Kubernetes SDK](https://kfp-kubernetes.readthedocs.io/en/kfp-kubernetes-1.4.0/)
- [TrustyAI](https://github.com/trustyai-explainability)
- [DVC](https://dvc.org/doc)
- [ModelScan](https://github.com/protectai/modelscan)
- [KServe](https://kserve.github.io/website/master/modelserving/control_plane/)
- [Feast](https://docs.feast.dev/)

## Glossary
- **MLOps** - The process of managing machine learning models in production.
- **ETL (Extract, Transform, Load)** - A process to collect, clean, and store data.
- **EDA (Exploratory Data Analysis)** - Analyzing data to understand patterns and issues.
- **Feature Store** - A centralized system to manage and serve machine learning features.
- **Feature Engineering** - Creating and modifying data features to improve models.
- **Data Pipeline** - An automated workflow for processing and moving data.
- **Neural Network** - A machine learning model inspired by the human brain.
- **Hyperparameter Tuning** - Adjusting model settings to improve performance.
- **Training** - Teaching a machine learning model using data.
- **Inference** - Using a trained model to make predictions.
- **Model Pipeline** - A workflow that automates training, evaluation, and deployment.
- **Kubeflow** - A tool for managing ML workflows on Kubernetes.
- **ArgoCD** - A GitOps tool for automating deployments.
- **Model Registry** - A system to store and manage different versions of models.
- **Canary Deployment** - Releasing a new model to a small group before full rollout.
- **Shadow Deployment** - Running a new model in parallel without affecting users.
- **Model Drift** - A decrease in model accuracy due to changing data.
- **Bias Detection** - Identifying unfair or unintended biases in models.
- **SHAP (Shapley Additive Explanations)** - A method to explain model predictions.
- **Counterfactuals** - Showing "what-if" scenarios to explain predictions.